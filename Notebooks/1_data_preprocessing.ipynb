{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5bb7114-2255-4777-9f6c-435697ea2234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üì• 1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a98063ab-e8a6-4bdb-b5c0-2ab280048d65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Time: double (nullable = true)\n |-- V1: double (nullable = true)\n |-- V2: double (nullable = true)\n |-- V3: double (nullable = true)\n |-- V4: double (nullable = true)\n |-- V5: double (nullable = true)\n |-- V6: double (nullable = true)\n |-- V7: double (nullable = true)\n |-- V8: double (nullable = true)\n |-- V9: double (nullable = true)\n |-- V10: double (nullable = true)\n |-- V11: double (nullable = true)\n |-- V12: double (nullable = true)\n |-- V13: double (nullable = true)\n |-- V14: double (nullable = true)\n |-- V15: double (nullable = true)\n |-- V16: double (nullable = true)\n |-- V17: double (nullable = true)\n |-- V18: double (nullable = true)\n |-- V19: double (nullable = true)\n |-- V20: double (nullable = true)\n |-- V21: double (nullable = true)\n |-- V22: double (nullable = true)\n |-- V23: double (nullable = true)\n |-- V24: double (nullable = true)\n |-- V25: double (nullable = true)\n |-- V26: double (nullable = true)\n |-- V27: double (nullable = true)\n |-- V28: double (nullable = true)\n |-- Amount: double (nullable = true)\n |-- Class: integer (nullable = true)\n\nOut[1]: DataFrame[Time: double, V1: double, V2: double, V3: double, V4: double, V5: double, V6: double, V7: double, V8: double, V9: double, V10: double, V11: double, V12: double, V13: double, V14: double, V15: double, V16: double, V17: double, V18: double, V19: double, V20: double, V21: double, V22: double, V23: double, V24: double, V25: double, V26: double, V27: double, V28: double, Amount: double, Class: int]"
     ]
    }
   ],
   "source": [
    "# Load csv file\n",
    "\n",
    "df = spark.read.csv(\"/FileStore/tables/creditcard.csv\", header=True, inferSchema=True )\n",
    "df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c58f4557-1a3a-4eb2-ad78-95b8dfd0b9bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üîç Check for missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f11e9f70-6984-4f34-8054-7af3a007e01d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+------+-----+\n|Time| V1| V2| V3| V4| V5| V6| V7| V8| V9|V10|V11|V12|V13|V14|V15|V16|V17|V18|V19|V20|V21|V22|V23|V24|V25|V26|V27|V28|Amount|Class|\n+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+------+-----+\n|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|     0|    0|\n+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c1212e0-61a4-4bb3-922c-fe60a3ac28d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "There are no missing values from the credit card data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b9b7905-e1bc-41d5-b1c7-74b4c989ff4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ‚öñÔ∏è 3. Check Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3957c1c6-6157-4019-bac2-51001f9f68ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n|Class| count|\n+-----+------+\n|    1|   492|\n|    0|284315|\n+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Class\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e4cb6bf-e00a-465b-a13c-2d28fff6dc85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The dataset shows a significant imbalance, with fraudulent transactions making up only 0.17% of the total. This disproportion can lead to machine learning models that are less effective at detecting fraud, as they tend to favor the majority class. While techniques like SMOTE are often used to balance datasets by creating synthetic examples of the minority class, PySpark does not currently support this method. As a practical alternative, I have implemented undersampling to reduce the number of legitimate transactions and help the model better identify fraudulent activity.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03c799ea-b5f2-42b5-ac08-27a5463b8625",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72bc34f2-e447-43e2-a836-77244ce13968",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n|Class|count|\n+-----+-----+\n|    1|  492|\n|    0| 1932|\n+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "fraud = df.filter(df.Class == 1)\n",
    "non_fraud = df.filter(df.Class == 0)\n",
    "\n",
    "ratio = 4\n",
    "non_fraud_sample = non_fraud.sample(False, ratio * fraud.count() / non_fraud.count(), seed=42)\n",
    "\n",
    "df_balanced = fraud.union(non_fraud_sample)\n",
    "df_balanced.groupBy(\"Class\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00f524ee-25cc-44a8-adb9-acee55af84e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üíæ 5. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c691e8ae-11cb-451b-86ae-dcf26ab90750",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_balanced.write.mode(\"Overwrite\").parquet(\"/FileStore/tables/creditcard_balanced.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1_data_preprocessing.ipynb",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
