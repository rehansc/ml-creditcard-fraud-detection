{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48345a6c-2130-420d-8872-af5a29f21bcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ✅ 1. Load Your Best Model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d217992b-5ecf-47e2-8836-ea9656774726",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "rf_model = PipelineModel.load(\"dbfs:/FileStore/models/rf_fraud_model\")\n",
    "\n",
    "# Load test data\n",
    "test_df = spark.read.parquet(\"dbfs:/FileStore/tables/creditcard_balanced.parquet\")  # or reload split if saved\n",
    "_, test_df = test_df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3c50f08-ff5c-43ea-aa17-f85d914cb8fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ✅ 2. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae6dbb3e-14ee-4433-bf36-5d55b22bf6be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----+\n|prediction|         probability|Class|\n+----------+--------------------+-----+\n|       0.0|[0.97451749948561...|    0|\n|       0.0|[0.97265965591382...|    0|\n|       0.0|[0.97425569773591...|    0|\n|       0.0|[0.97451749948561...|    0|\n|       0.0|[0.97265965591382...|    0|\n|       0.0|[0.97451749948561...|    0|\n|       0.0|[0.96898303127787...|    0|\n|       0.0|[0.98177760493561...|    0|\n|       0.0|[0.97486593991005...|    0|\n|       0.0|[0.95843885569027...|    0|\n|       0.0|[0.55685669360349...|    0|\n|       0.0|[0.77312075219004...|    0|\n|       0.0|[0.97624282729789...|    0|\n|       0.0|[0.97006268524934...|    0|\n|       0.0|[0.97070835909016...|    0|\n|       0.0|[0.97486593991005...|    0|\n|       0.0|[0.97451749948561...|    0|\n|       0.0|[0.97624282729789...|    0|\n|       0.0|[0.97451749948561...|    0|\n|       0.0|[0.97451749948561...|    0|\n+----------+--------------------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "predictions = rf_model.transform(test_df)\n",
    "predictions.select(\"prediction\", \"probability\", \"Class\").show(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6dff16d-a43c-47eb-a070-477dc2cf245e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ✅ 3. Evaluation Metrics: Precision, Recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f31fe502-5091-4716-8f75-37afb8e3972c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9691\nRecall: 0.9973\nF1 Score: 0.9725\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Class\", predictionCol=\"prediction\")\n",
    "\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"precisionByLabel\"})\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"recallByLabel\"})\n",
    "f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a0c6f5a-9ec2-43e4-acc6-aff983a6d075",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Precision: Out of all transactions the model flagged as fraud, 96.91% were actually fraud. High precision means few false alarms.\n",
    "Recall: Out of all actual fraud transactions, the model correctly detected 99.73% of them. High recall means very few missed frauds.\n",
    "F1 Score: The harmonic mean of precision and recall. It balances the two, giving you a single number to understand overall accuracy regarding fraud classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18d71319-9373-4752-8604-9e89aac523d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ✅ 4. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8805bad5-7bc5-450e-a7cb-02c0a226cfae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n|Class|prediction|count|\n+-----+----------+-----+\n|    0|       0.0|  376|\n|    0|       1.0|    1|\n|    1|       0.0|   12|\n|    1|       1.0|   93|\n+-----+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "predictions.groupBy(\"Class\", \"prediction\").count().orderBy(\"Class\", \"prediction\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "206804c5-a6b5-4f76-a8ed-217d8438788d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ✅ 5. ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88aa7e0f-45ca-4d33-a521-81d3d08ef51c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9859\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator_roc = BinaryClassificationEvaluator(labelCol=\"Class\", metricName=\"areaUnderROC\")\n",
    "roc_auc = evaluator_roc.evaluate(predictions)\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4_model_evaluation.ipynb",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}